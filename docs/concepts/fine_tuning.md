# Fine tuning

See [Openai Fine Tuning](https://cookbook.openai.com/examples/how_to_finetune_chat_models).

RAG, Retrieval Augnented Generation, can be used to supplement the query with contextual data collected from our data sources. This resolves the issue that the LLM will not have been trained on our data.

What can be done is to fine tune the LLM with our own dataset so that the LLM is trained to understand our data.

Costs and time are important factors to consider, yet for many organisations, having a specialist LLM for their data is advantageous.

<br>